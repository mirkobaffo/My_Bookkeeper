<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="it"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../../jacoco-resources/report.gif" type="image/gif"/><title>SingleDirectoryDbLedgerStorage.java</title><link rel="stylesheet" href="../../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../../index.html" class="el_report">Tests</a> &gt; <a href="../index.html" class="el_bundle">bookkeeper-server</a> &gt; <a href="index.source.html" class="el_package">org.apache.bookkeeper.bookie.storage.ldb</a> &gt; <span class="el_source">SingleDirectoryDbLedgerStorage.java</span></div><h1>SingleDirectoryDbLedgerStorage.java</h1><pre class="source lang-java linenums">/**
 *
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * &quot;License&quot;); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
 * under the License.
 *
 */
package org.apache.bookkeeper.bookie.storage.ldb;

import static com.google.common.base.Preconditions.checkArgument;

import com.google.common.annotations.VisibleForTesting;
import com.google.common.collect.Lists;
import com.google.protobuf.ByteString;

import io.netty.buffer.ByteBuf;
import io.netty.buffer.ByteBufAllocator;
import io.netty.buffer.Unpooled;
import io.netty.util.concurrent.DefaultThreadFactory;

import java.io.File;
import java.io.IOException;
import java.util.Collections;
import java.util.List;
import java.util.PrimitiveIterator.OfLong;
import java.util.concurrent.CopyOnWriteArrayList;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.locks.ReentrantLock;
import java.util.concurrent.locks.StampedLock;

import org.apache.bookkeeper.bookie.Bookie;
import org.apache.bookkeeper.bookie.Bookie.NoEntryException;
import org.apache.bookkeeper.bookie.BookieException;
import org.apache.bookkeeper.bookie.BookieException.OperationRejectedException;
import org.apache.bookkeeper.bookie.CheckpointSource;
import org.apache.bookkeeper.bookie.CheckpointSource.Checkpoint;
import org.apache.bookkeeper.bookie.Checkpointer;
import org.apache.bookkeeper.bookie.CompactableLedgerStorage;
import org.apache.bookkeeper.bookie.EntryLocation;
import org.apache.bookkeeper.bookie.EntryLogger;
import org.apache.bookkeeper.bookie.GarbageCollectionStatus;
import org.apache.bookkeeper.bookie.GarbageCollectorThread;
import org.apache.bookkeeper.bookie.LastAddConfirmedUpdateNotification;
import org.apache.bookkeeper.bookie.LedgerCache;
import org.apache.bookkeeper.bookie.LedgerDirsManager;
import org.apache.bookkeeper.bookie.LedgerDirsManager.LedgerDirsListener;
import org.apache.bookkeeper.bookie.LedgerEntryPage;
import org.apache.bookkeeper.bookie.StateManager;
import org.apache.bookkeeper.bookie.storage.ldb.DbLedgerStorageDataFormats.LedgerData;
import org.apache.bookkeeper.bookie.storage.ldb.KeyValueStorage.Batch;
import org.apache.bookkeeper.common.util.Watcher;
import org.apache.bookkeeper.conf.ServerConfiguration;
import org.apache.bookkeeper.meta.LedgerManager;
import org.apache.bookkeeper.proto.BookieProtocol;
import org.apache.bookkeeper.stats.OpStatsLogger;
import org.apache.bookkeeper.stats.StatsLogger;
import org.apache.bookkeeper.util.MathUtils;
import org.apache.bookkeeper.util.collections.ConcurrentLongHashMap;
import org.apache.commons.lang.mutable.MutableLong;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

/**
 * Single directory implementation of LedgerStorage that uses RocksDB to keep the indexes for entries stored in
 * EntryLogs.
 *
 * &lt;p&gt;This is meant only to be used from {@link DbLedgerStorage}.
 */
public class SingleDirectoryDbLedgerStorage implements CompactableLedgerStorage {
    private final EntryLogger entryLogger;

    private final LedgerMetadataIndex ledgerIndex;
    private final EntryLocationIndex entryLocationIndex;

    private final ConcurrentLongHashMap&lt;TransientLedgerInfo&gt; transientLedgerInfoCache;

    private final GarbageCollectorThread gcThread;

    // Write cache where all new entries are inserted into
    protected volatile WriteCache writeCache;

    // Write cache that is used to swap with writeCache during flushes
    protected volatile WriteCache writeCacheBeingFlushed;

    // Cache where we insert entries for speculative reading
    private final ReadCache readCache;

<span class="nc" id="L105">    private final StampedLock writeCacheRotationLock = new StampedLock();</span>

<span class="nc" id="L107">    protected final ReentrantLock flushMutex = new ReentrantLock();</span>

<span class="nc" id="L109">    protected final AtomicBoolean hasFlushBeenTriggered = new AtomicBoolean(false);</span>
<span class="nc" id="L110">    private final AtomicBoolean isFlushOngoing = new AtomicBoolean(false);</span>

<span class="nc" id="L112">    private final ExecutorService executor = Executors.newSingleThreadExecutor(new DefaultThreadFactory(&quot;db-storage&quot;));</span>

    // Executor used to for db index cleanup
<span class="nc" id="L115">    private final ScheduledExecutorService cleanupExecutor = Executors</span>
<span class="nc" id="L116">            .newSingleThreadScheduledExecutor(new DefaultThreadFactory(&quot;db-storage-cleanup&quot;));</span>

<span class="nc" id="L118">    private final CopyOnWriteArrayList&lt;LedgerDeletionListener&gt; ledgerDeletionListeners = Lists</span>
<span class="nc" id="L119">            .newCopyOnWriteArrayList();</span>

    private final CheckpointSource checkpointSource;
<span class="nc" id="L122">    private Checkpoint lastCheckpoint = Checkpoint.MIN;</span>

    private final long writeCacheMaxSize;
    private final long readCacheMaxSize;
    private final int readAheadCacheBatchSize;

    private final long maxThrottleTimeNanos;

    private final DbLedgerStorageStats dbLedgerStorageStats;

    static final String READ_AHEAD_CACHE_BATCH_SIZE = &quot;dbStorage_readAheadCacheBatchSize&quot;;
    private static final int DEFAULT_READ_AHEAD_CACHE_BATCH_SIZE = 100;

<span class="nc" id="L135">    private static final long DEFAULT_MAX_THROTTLE_TIME_MILLIS = TimeUnit.SECONDS.toMillis(10);</span>

    private final long maxReadAheadBytesSize;

    public SingleDirectoryDbLedgerStorage(ServerConfiguration conf, LedgerManager ledgerManager,
            LedgerDirsManager ledgerDirsManager, LedgerDirsManager indexDirsManager, StateManager stateManager,
            CheckpointSource checkpointSource, Checkpointer checkpointer, StatsLogger statsLogger,
            ByteBufAllocator allocator, ScheduledExecutorService gcExecutor, long writeCacheSize, long readCacheSize)
<span class="nc" id="L143">            throws IOException {</span>

<span class="nc bnc" id="L145" title="All 2 branches missed.">        checkArgument(ledgerDirsManager.getAllLedgerDirs().size() == 1,</span>
                &quot;Db implementation only allows for one storage dir&quot;);

<span class="nc" id="L148">        String baseDir = ledgerDirsManager.getAllLedgerDirs().get(0).toString();</span>
<span class="nc" id="L149">        log.info(&quot;Creating single directory db ledger storage on {}&quot;, baseDir);</span>

<span class="nc" id="L151">        this.writeCacheMaxSize = writeCacheSize;</span>
<span class="nc" id="L152">        this.writeCache = new WriteCache(allocator, writeCacheMaxSize / 2);</span>
<span class="nc" id="L153">        this.writeCacheBeingFlushed = new WriteCache(allocator, writeCacheMaxSize / 2);</span>

<span class="nc" id="L155">        this.checkpointSource = checkpointSource;</span>

<span class="nc" id="L157">        readCacheMaxSize = readCacheSize;</span>
<span class="nc" id="L158">        readAheadCacheBatchSize = conf.getInt(READ_AHEAD_CACHE_BATCH_SIZE, DEFAULT_READ_AHEAD_CACHE_BATCH_SIZE);</span>

        // Do not attempt to perform read-ahead more than half the total size of the cache
<span class="nc" id="L161">        maxReadAheadBytesSize = readCacheMaxSize / 2;</span>

<span class="nc" id="L163">        long maxThrottleTimeMillis = conf.getLong(DbLedgerStorage.MAX_THROTTLE_TIME_MILLIS,</span>
                DEFAULT_MAX_THROTTLE_TIME_MILLIS);
<span class="nc" id="L165">        maxThrottleTimeNanos = TimeUnit.MILLISECONDS.toNanos(maxThrottleTimeMillis);</span>

<span class="nc" id="L167">        readCache = new ReadCache(allocator, readCacheMaxSize);</span>

<span class="nc" id="L169">        ledgerIndex = new LedgerMetadataIndex(conf, KeyValueStorageRocksDB.factory, baseDir, statsLogger);</span>
<span class="nc" id="L170">        entryLocationIndex = new EntryLocationIndex(conf, KeyValueStorageRocksDB.factory, baseDir, statsLogger);</span>

<span class="nc" id="L172">        transientLedgerInfoCache = new ConcurrentLongHashMap&lt;&gt;(16 * 1024,</span>
<span class="nc" id="L173">                Runtime.getRuntime().availableProcessors() * 2);</span>
<span class="nc" id="L174">        cleanupExecutor.scheduleAtFixedRate(this::cleanupStaleTransientLedgerInfo,</span>
                TransientLedgerInfo.LEDGER_INFO_CACHING_TIME_MINUTES,
                TransientLedgerInfo.LEDGER_INFO_CACHING_TIME_MINUTES, TimeUnit.MINUTES);

<span class="nc" id="L178">        entryLogger = new EntryLogger(conf, ledgerDirsManager, null, statsLogger, allocator);</span>
<span class="nc" id="L179">        gcThread = new GarbageCollectorThread(conf, ledgerManager, this, statsLogger);</span>

<span class="nc" id="L181">        dbLedgerStorageStats = new DbLedgerStorageStats(</span>
            statsLogger,
<span class="nc" id="L183">            () -&gt; writeCache.size() + writeCacheBeingFlushed.size(),</span>
<span class="nc" id="L184">            () -&gt; writeCache.count() + writeCacheBeingFlushed.count(),</span>
<span class="nc" id="L185">            () -&gt; readCache.size(),</span>
<span class="nc" id="L186">            () -&gt; readCache.count()</span>
        );
<span class="nc" id="L188">        ledgerDirsManager.addLedgerDirsListener(getLedgerDirsListener());</span>
<span class="nc" id="L189">    }</span>

    @Override
    public void initialize(ServerConfiguration conf, LedgerManager ledgerManager, LedgerDirsManager ledgerDirsManager,
            LedgerDirsManager indexDirsManager, StateManager stateManager, CheckpointSource checkpointSource,
            Checkpointer checkpointer, StatsLogger statsLogger,
            ByteBufAllocator allocator) throws IOException {
        /// Initialized in constructor
<span class="nc" id="L197">    }</span>

    /**
     * Evict all the ledger info object that were not used recently.
     */
    private void cleanupStaleTransientLedgerInfo() {
<span class="nc" id="L203">        transientLedgerInfoCache.removeIf((ledgerId, ledgerInfo) -&gt; {</span>
<span class="nc" id="L204">            boolean isStale = ledgerInfo.isStale();</span>
<span class="nc bnc" id="L205" title="All 2 branches missed.">            if (isStale) {</span>
<span class="nc" id="L206">                ledgerInfo.close();</span>
            }

<span class="nc" id="L209">            return isStale;</span>
        });
<span class="nc" id="L211">    }</span>

    @Override
    public void start() {
<span class="nc" id="L215">        gcThread.start();</span>
<span class="nc" id="L216">    }</span>

    @Override
    public void forceGC() {
<span class="nc" id="L220">        gcThread.enableForceGC();</span>
<span class="nc" id="L221">    }</span>

    @Override
    public boolean isInForceGC() {
<span class="nc" id="L225">        return gcThread.isInForceGC();</span>
    }

    @Override
    public void shutdown() throws InterruptedException {
        try {
<span class="nc" id="L231">            flush();</span>

<span class="nc" id="L233">            gcThread.shutdown();</span>
<span class="nc" id="L234">            entryLogger.shutdown();</span>

<span class="nc" id="L236">            cleanupExecutor.shutdown();</span>
<span class="nc" id="L237">            cleanupExecutor.awaitTermination(1, TimeUnit.SECONDS);</span>

<span class="nc" id="L239">            ledgerIndex.close();</span>
<span class="nc" id="L240">            entryLocationIndex.close();</span>

<span class="nc" id="L242">            writeCache.close();</span>
<span class="nc" id="L243">            writeCacheBeingFlushed.close();</span>
<span class="nc" id="L244">            readCache.close();</span>
<span class="nc" id="L245">            executor.shutdown();</span>

<span class="nc" id="L247">        } catch (IOException e) {</span>
<span class="nc" id="L248">            log.error(&quot;Error closing db storage&quot;, e);</span>
<span class="nc" id="L249">        }</span>
<span class="nc" id="L250">    }</span>

    @Override
    public boolean ledgerExists(long ledgerId) throws IOException {
        try {
<span class="nc" id="L255">            LedgerData ledgerData = ledgerIndex.get(ledgerId);</span>
<span class="nc bnc" id="L256" title="All 2 branches missed.">            if (log.isDebugEnabled()) {</span>
<span class="nc" id="L257">                log.debug(&quot;Ledger exists. ledger: {} : {}&quot;, ledgerId, ledgerData.getExists());</span>
            }
<span class="nc" id="L259">            return ledgerData.getExists();</span>
<span class="nc" id="L260">        } catch (Bookie.NoLedgerException nle) {</span>
            // ledger does not exist
<span class="nc" id="L262">            return false;</span>
        }
    }

    @Override
    public boolean isFenced(long ledgerId) throws IOException {
<span class="nc bnc" id="L268" title="All 2 branches missed.">        if (log.isDebugEnabled()) {</span>
<span class="nc" id="L269">            log.debug(&quot;isFenced. ledger: {}&quot;, ledgerId);</span>
        }
<span class="nc" id="L271">        return ledgerIndex.get(ledgerId).getFenced();</span>
    }

    @Override
    public boolean setFenced(long ledgerId) throws IOException {
<span class="nc bnc" id="L276" title="All 2 branches missed.">        if (log.isDebugEnabled()) {</span>
<span class="nc" id="L277">            log.debug(&quot;Set fenced. ledger: {}&quot;, ledgerId);</span>
        }
<span class="nc" id="L279">        boolean changed = ledgerIndex.setFenced(ledgerId);</span>
<span class="nc bnc" id="L280" title="All 2 branches missed.">        if (changed) {</span>
            // notify all the watchers if a ledger is fenced
<span class="nc" id="L282">            TransientLedgerInfo ledgerInfo = transientLedgerInfoCache.get(ledgerId);</span>
<span class="nc bnc" id="L283" title="All 2 branches missed.">            if (null != ledgerInfo) {</span>
<span class="nc" id="L284">                ledgerInfo.notifyWatchers(Long.MAX_VALUE);</span>
            }
        }
<span class="nc" id="L287">        return changed;</span>
    }

    @Override
    public void setMasterKey(long ledgerId, byte[] masterKey) throws IOException {
<span class="nc bnc" id="L292" title="All 2 branches missed.">        if (log.isDebugEnabled()) {</span>
<span class="nc" id="L293">            log.debug(&quot;Set master key. ledger: {}&quot;, ledgerId);</span>
        }
<span class="nc" id="L295">        ledgerIndex.setMasterKey(ledgerId, masterKey);</span>
<span class="nc" id="L296">    }</span>

    @Override
    public byte[] readMasterKey(long ledgerId) throws IOException, BookieException {
<span class="nc bnc" id="L300" title="All 2 branches missed.">        if (log.isDebugEnabled()) {</span>
<span class="nc" id="L301">            log.debug(&quot;Read master key. ledger: {}&quot;, ledgerId);</span>
        }
<span class="nc" id="L303">        return ledgerIndex.get(ledgerId).getMasterKey().toByteArray();</span>
    }

    @Override
    public long addEntry(ByteBuf entry) throws IOException, BookieException {
<span class="nc" id="L308">        long startTime = MathUtils.nowInNano();</span>

<span class="nc" id="L310">        long ledgerId = entry.getLong(entry.readerIndex());</span>
<span class="nc" id="L311">        long entryId = entry.getLong(entry.readerIndex() + 8);</span>
<span class="nc" id="L312">        long lac = entry.getLong(entry.readerIndex() + 16);</span>

<span class="nc bnc" id="L314" title="All 2 branches missed.">        if (log.isDebugEnabled()) {</span>
<span class="nc" id="L315">            log.debug(&quot;Add entry. {}@{}, lac = {}&quot;, ledgerId, entryId, lac);</span>
        }

        // First we try to do an optimistic locking to get access to the current write cache.
        // This is based on the fact that the write cache is only being rotated (swapped) every 1 minute. During the
        // rest of the time, we can have multiple thread using the optimistic lock here without interfering.
<span class="nc" id="L321">        long stamp = writeCacheRotationLock.tryOptimisticRead();</span>
<span class="nc" id="L322">        boolean inserted = false;</span>

<span class="nc" id="L324">        inserted = writeCache.put(ledgerId, entryId, entry);</span>
<span class="nc bnc" id="L325" title="All 2 branches missed.">        if (!writeCacheRotationLock.validate(stamp)) {</span>
            // The write cache was rotated while we were inserting. We need to acquire the proper read lock and repeat
            // the operation because we might have inserted in a write cache that was already being flushed and cleared,
            // without being sure about this last entry being flushed or not.
<span class="nc" id="L329">            stamp = writeCacheRotationLock.readLock();</span>
            try {
<span class="nc" id="L331">                inserted = writeCache.put(ledgerId, entryId, entry);</span>
            } finally {
<span class="nc" id="L333">                writeCacheRotationLock.unlockRead(stamp);</span>
            }
        }

<span class="nc bnc" id="L337" title="All 2 branches missed.">        if (!inserted) {</span>
<span class="nc" id="L338">            triggerFlushAndAddEntry(ledgerId, entryId, entry);</span>
        }

        // after successfully insert the entry, update LAC and notify the watchers
<span class="nc" id="L342">        updateCachedLacIfNeeded(ledgerId, lac);</span>

<span class="nc" id="L344">        recordSuccessfulEvent(dbLedgerStorageStats.getAddEntryStats(), startTime);</span>
<span class="nc" id="L345">        return entryId;</span>
    }

    private void triggerFlushAndAddEntry(long ledgerId, long entryId, ByteBuf entry)
            throws IOException, BookieException {
<span class="nc" id="L350">        dbLedgerStorageStats.getThrottledWriteRequests().inc();</span>
<span class="nc" id="L351">        long absoluteTimeoutNanos = System.nanoTime() + maxThrottleTimeNanos;</span>

<span class="nc bnc" id="L353" title="All 2 branches missed.">        while (System.nanoTime() &lt; absoluteTimeoutNanos) {</span>
            // Write cache is full, we need to trigger a flush so that it gets rotated
            // If the flush has already been triggered or flush has already switched the
            // cache, we don't need to trigger another flush
<span class="nc bnc" id="L357" title="All 4 branches missed.">            if (!isFlushOngoing.get() &amp;&amp; hasFlushBeenTriggered.compareAndSet(false, true)) {</span>
                // Trigger an early flush in background
<span class="nc" id="L359">                log.info(&quot;Write cache is full, triggering flush&quot;);</span>
<span class="nc" id="L360">                executor.execute(() -&gt; {</span>
                        try {
<span class="nc" id="L362">                            flush();</span>
<span class="nc" id="L363">                        } catch (IOException e) {</span>
<span class="nc" id="L364">                            log.error(&quot;Error during flush&quot;, e);</span>
<span class="nc" id="L365">                        }</span>
<span class="nc" id="L366">                    });</span>
            }

<span class="nc" id="L369">            long stamp = writeCacheRotationLock.readLock();</span>
            try {
<span class="nc bnc" id="L371" title="All 2 branches missed.">                if (writeCache.put(ledgerId, entryId, entry)) {</span>
                    // We succeeded in putting the entry in write cache in the
<span class="nc" id="L373">                    return;</span>
                }
            } finally {
<span class="nc" id="L376">                writeCacheRotationLock.unlockRead(stamp);</span>
            }

            // Wait some time and try again
            try {
<span class="nc" id="L381">                Thread.sleep(1);</span>
<span class="nc" id="L382">            } catch (InterruptedException e) {</span>
<span class="nc" id="L383">                Thread.currentThread().interrupt();</span>
<span class="nc" id="L384">                throw new IOException(&quot;Interrupted when adding entry &quot; + ledgerId + &quot;@&quot; + entryId);</span>
<span class="nc" id="L385">            }</span>
<span class="nc" id="L386">        }</span>

        // Timeout expired and we weren't able to insert in write cache
<span class="nc" id="L389">        dbLedgerStorageStats.getRejectedWriteRequests().inc();</span>
<span class="nc" id="L390">        throw new OperationRejectedException();</span>
    }

    @Override
    public ByteBuf getEntry(long ledgerId, long entryId) throws IOException {
<span class="nc" id="L395">        long startTime = MathUtils.nowInNano();</span>
<span class="nc bnc" id="L396" title="All 2 branches missed.">        if (log.isDebugEnabled()) {</span>
<span class="nc" id="L397">            log.debug(&quot;Get Entry: {}@{}&quot;, ledgerId, entryId);</span>
        }

<span class="nc bnc" id="L400" title="All 2 branches missed.">        if (entryId == BookieProtocol.LAST_ADD_CONFIRMED) {</span>
<span class="nc" id="L401">            return getLastEntry(ledgerId);</span>
        }

        // We need to try to read from both write caches, since recent entries could be found in either of the two. The
        // write caches are already thread safe on their own, here we just need to make sure we get references to both
        // of them. Using an optimistic lock since the read lock is always free, unless we're swapping the caches.
<span class="nc" id="L407">        long stamp = writeCacheRotationLock.tryOptimisticRead();</span>
<span class="nc" id="L408">        WriteCache localWriteCache = writeCache;</span>
<span class="nc" id="L409">        WriteCache localWriteCacheBeingFlushed = writeCacheBeingFlushed;</span>
<span class="nc bnc" id="L410" title="All 2 branches missed.">        if (!writeCacheRotationLock.validate(stamp)) {</span>
            // Fallback to regular read lock approach
<span class="nc" id="L412">            stamp = writeCacheRotationLock.readLock();</span>
            try {
<span class="nc" id="L414">                localWriteCache = writeCache;</span>
<span class="nc" id="L415">                localWriteCacheBeingFlushed = writeCacheBeingFlushed;</span>
            } finally {
<span class="nc" id="L417">                writeCacheRotationLock.unlockRead(stamp);</span>
            }
        }

        // First try to read from the write cache of recent entries
<span class="nc" id="L422">        ByteBuf entry = localWriteCache.get(ledgerId, entryId);</span>
<span class="nc bnc" id="L423" title="All 2 branches missed.">        if (entry != null) {</span>
<span class="nc" id="L424">            recordSuccessfulEvent(dbLedgerStorageStats.getReadCacheHitStats(), startTime);</span>
<span class="nc" id="L425">            recordSuccessfulEvent(dbLedgerStorageStats.getReadEntryStats(), startTime);</span>
<span class="nc" id="L426">            return entry;</span>
        }

        // If there's a flush going on, the entry might be in the flush buffer
<span class="nc" id="L430">        entry = localWriteCacheBeingFlushed.get(ledgerId, entryId);</span>
<span class="nc bnc" id="L431" title="All 2 branches missed.">        if (entry != null) {</span>
<span class="nc" id="L432">            recordSuccessfulEvent(dbLedgerStorageStats.getReadCacheHitStats(), startTime);</span>
<span class="nc" id="L433">            recordSuccessfulEvent(dbLedgerStorageStats.getReadEntryStats(), startTime);</span>
<span class="nc" id="L434">            return entry;</span>
        }

        // Try reading from read-ahead cache
<span class="nc" id="L438">        entry = readCache.get(ledgerId, entryId);</span>
<span class="nc bnc" id="L439" title="All 2 branches missed.">        if (entry != null) {</span>
<span class="nc" id="L440">            recordSuccessfulEvent(dbLedgerStorageStats.getReadCacheHitStats(), startTime);</span>
<span class="nc" id="L441">            recordSuccessfulEvent(dbLedgerStorageStats.getReadEntryStats(), startTime);</span>
<span class="nc" id="L442">            return entry;</span>
        }

        // Read from main storage
        long entryLocation;
        try {
<span class="nc" id="L448">            entryLocation = entryLocationIndex.getLocation(ledgerId, entryId);</span>
<span class="nc bnc" id="L449" title="All 2 branches missed.">            if (entryLocation == 0) {</span>
<span class="nc" id="L450">                throw new NoEntryException(ledgerId, entryId);</span>
            }
<span class="nc" id="L452">            entry = entryLogger.readEntry(ledgerId, entryId, entryLocation);</span>
<span class="nc" id="L453">        } catch (NoEntryException e) {</span>
<span class="nc" id="L454">            recordFailedEvent(dbLedgerStorageStats.getReadEntryStats(), startTime);</span>
<span class="nc" id="L455">            throw e;</span>
<span class="nc" id="L456">        }</span>

<span class="nc" id="L458">        readCache.put(ledgerId, entryId, entry);</span>

        // Try to read more entries
<span class="nc" id="L461">        long nextEntryLocation = entryLocation + 4 /* size header */ + entry.readableBytes();</span>
<span class="nc" id="L462">        fillReadAheadCache(ledgerId, entryId + 1, nextEntryLocation);</span>

<span class="nc" id="L464">        recordSuccessfulEvent(dbLedgerStorageStats.getReadCacheMissStats(), startTime);</span>
<span class="nc" id="L465">        recordSuccessfulEvent(dbLedgerStorageStats.getReadEntryStats(), startTime);</span>
<span class="nc" id="L466">        return entry;</span>
    }

    private void fillReadAheadCache(long orginalLedgerId, long firstEntryId, long firstEntryLocation) {
        try {
<span class="nc" id="L471">            long firstEntryLogId = (firstEntryLocation &gt;&gt; 32);</span>
<span class="nc" id="L472">            long currentEntryLogId = firstEntryLogId;</span>
<span class="nc" id="L473">            long currentEntryLocation = firstEntryLocation;</span>
<span class="nc" id="L474">            int count = 0;</span>
<span class="nc" id="L475">            long size = 0;</span>

<span class="nc bnc" id="L477" title="All 6 branches missed.">            while (count &lt; readAheadCacheBatchSize</span>
                    &amp;&amp; size &lt; maxReadAheadBytesSize
                    &amp;&amp; currentEntryLogId == firstEntryLogId) {
<span class="nc" id="L480">                ByteBuf entry = entryLogger.internalReadEntry(orginalLedgerId, firstEntryId, currentEntryLocation,</span>
                        false /* validateEntry */);

                try {
<span class="nc" id="L484">                    long currentEntryLedgerId = entry.getLong(0);</span>
<span class="nc" id="L485">                    long currentEntryId = entry.getLong(8);</span>

<span class="nc bnc" id="L487" title="All 2 branches missed.">                    if (currentEntryLedgerId != orginalLedgerId) {</span>
                        // Found an entry belonging to a different ledger, stopping read-ahead
                        break;
                    }

                    // Insert entry in read cache
<span class="nc" id="L493">                    readCache.put(orginalLedgerId, currentEntryId, entry);</span>

<span class="nc" id="L495">                    count++;</span>
<span class="nc" id="L496">                    firstEntryId++;</span>
<span class="nc" id="L497">                    size += entry.readableBytes();</span>

<span class="nc" id="L499">                    currentEntryLocation += 4 + entry.readableBytes();</span>
<span class="nc" id="L500">                    currentEntryLogId = currentEntryLocation &gt;&gt; 32;</span>
                } finally {
<span class="nc" id="L502">                    entry.release();</span>
                }
<span class="nc" id="L504">            }</span>

<span class="nc" id="L506">            dbLedgerStorageStats.getReadAheadBatchCountStats().registerSuccessfulValue(count);</span>
<span class="nc" id="L507">            dbLedgerStorageStats.getReadAheadBatchSizeStats().registerSuccessfulValue(size);</span>
<span class="nc" id="L508">        } catch (Exception e) {</span>
<span class="nc bnc" id="L509" title="All 2 branches missed.">            if (log.isDebugEnabled()) {</span>
<span class="nc" id="L510">                log.debug(&quot;Exception during read ahead for ledger: {}: e&quot;, orginalLedgerId, e);</span>
            }
<span class="nc" id="L512">        }</span>
<span class="nc" id="L513">    }</span>

    public ByteBuf getLastEntry(long ledgerId) throws IOException {
<span class="nc" id="L516">        long startTime = MathUtils.nowInNano();</span>

<span class="nc" id="L518">        long stamp = writeCacheRotationLock.readLock();</span>
        try {
            // First try to read from the write cache of recent entries
<span class="nc" id="L521">            ByteBuf entry = writeCache.getLastEntry(ledgerId);</span>
<span class="nc bnc" id="L522" title="All 2 branches missed.">            if (entry != null) {</span>
<span class="nc bnc" id="L523" title="All 2 branches missed.">                if (log.isDebugEnabled()) {</span>
<span class="nc" id="L524">                    long foundLedgerId = entry.readLong(); // ledgedId</span>
<span class="nc" id="L525">                    long entryId = entry.readLong();</span>
<span class="nc" id="L526">                    entry.resetReaderIndex();</span>
<span class="nc bnc" id="L527" title="All 2 branches missed.">                    if (log.isDebugEnabled()) {</span>
<span class="nc" id="L528">                        log.debug(&quot;Found last entry for ledger {} in write cache: {}@{}&quot;, ledgerId, foundLedgerId,</span>
<span class="nc" id="L529">                                entryId);</span>
                    }
                }

<span class="nc" id="L533">                recordSuccessfulEvent(dbLedgerStorageStats.getReadCacheHitStats(), startTime);</span>
<span class="nc" id="L534">                recordSuccessfulEvent(dbLedgerStorageStats.getReadEntryStats(), startTime);</span>
<span class="nc" id="L535">                return entry;</span>
            }

            // If there's a flush going on, the entry might be in the flush buffer
<span class="nc" id="L539">            entry = writeCacheBeingFlushed.getLastEntry(ledgerId);</span>
<span class="nc bnc" id="L540" title="All 2 branches missed.">            if (entry != null) {</span>
<span class="nc bnc" id="L541" title="All 2 branches missed.">                if (log.isDebugEnabled()) {</span>
<span class="nc" id="L542">                    entry.readLong(); // ledgedId</span>
<span class="nc" id="L543">                    long entryId = entry.readLong();</span>
<span class="nc" id="L544">                    entry.resetReaderIndex();</span>
<span class="nc bnc" id="L545" title="All 2 branches missed.">                    if (log.isDebugEnabled()) {</span>
<span class="nc" id="L546">                        log.debug(&quot;Found last entry for ledger {} in write cache being flushed: {}&quot;, ledgerId, entryId);</span>
                    }
                }

<span class="nc" id="L550">                recordSuccessfulEvent(dbLedgerStorageStats.getReadCacheHitStats(), startTime);</span>
<span class="nc" id="L551">                recordSuccessfulEvent(dbLedgerStorageStats.getReadEntryStats(), startTime);</span>
<span class="nc" id="L552">                return entry;</span>
            }
        } finally {
<span class="nc" id="L555">            writeCacheRotationLock.unlockRead(stamp);</span>
        }

        // Search the last entry in storage
<span class="nc" id="L559">        long lastEntryId = entryLocationIndex.getLastEntryInLedger(ledgerId);</span>
<span class="nc bnc" id="L560" title="All 2 branches missed.">        if (log.isDebugEnabled()) {</span>
<span class="nc" id="L561">            log.debug(&quot;Found last entry for ledger {} in db: {}&quot;, ledgerId, lastEntryId);</span>
        }

<span class="nc" id="L564">        long entryLocation = entryLocationIndex.getLocation(ledgerId, lastEntryId);</span>
<span class="nc" id="L565">        ByteBuf content = entryLogger.readEntry(ledgerId, lastEntryId, entryLocation);</span>

<span class="nc" id="L567">        recordSuccessfulEvent(dbLedgerStorageStats.getReadCacheMissStats(), startTime);</span>
<span class="nc" id="L568">        recordSuccessfulEvent(dbLedgerStorageStats.getReadEntryStats(), startTime);</span>
<span class="nc" id="L569">        return content;</span>
    }

    @VisibleForTesting
    boolean isFlushRequired() {
<span class="nc" id="L574">        long stamp = writeCacheRotationLock.readLock();</span>
        try {
<span class="nc bnc" id="L576" title="All 2 branches missed.">            return !writeCache.isEmpty();</span>
        } finally {
<span class="nc" id="L578">            writeCacheRotationLock.unlockRead(stamp);</span>
        }
    }

    @Override
    public void checkpoint(Checkpoint checkpoint) throws IOException {
<span class="nc" id="L584">        Checkpoint thisCheckpoint = checkpointSource.newCheckpoint();</span>
<span class="nc bnc" id="L585" title="All 2 branches missed.">        if (lastCheckpoint.compareTo(checkpoint) &gt; 0) {</span>
<span class="nc" id="L586">            return;</span>
        }

<span class="nc" id="L589">        long startTime = MathUtils.nowInNano();</span>

        // Only a single flush operation can happen at a time
<span class="nc" id="L592">        flushMutex.lock();</span>

        try {
            // Swap the write cache so that writes can continue to happen while the flush is
            // ongoing
<span class="nc" id="L597">            swapWriteCache();</span>

<span class="nc" id="L599">            long sizeToFlush = writeCacheBeingFlushed.size();</span>
<span class="nc bnc" id="L600" title="All 2 branches missed.">            if (log.isDebugEnabled()) {</span>
<span class="nc" id="L601">                log.debug(&quot;Flushing entries. count: {} -- size {} Mb&quot;, writeCacheBeingFlushed.count(),</span>
<span class="nc" id="L602">                        sizeToFlush / 1024.0 / 1024);</span>
            }

            // Write all the pending entries into the entry logger and collect the offset
            // position for each entry

<span class="nc" id="L608">            Batch batch = entryLocationIndex.newBatch();</span>
<span class="nc" id="L609">            writeCacheBeingFlushed.forEach((ledgerId, entryId, entry) -&gt; {</span>
                try {
<span class="nc" id="L611">                    long location = entryLogger.addEntry(ledgerId, entry, true);</span>
<span class="nc" id="L612">                    entryLocationIndex.addLocation(batch, ledgerId, entryId, location);</span>
<span class="nc" id="L613">                } catch (IOException e) {</span>
<span class="nc" id="L614">                    throw new RuntimeException(e);</span>
<span class="nc" id="L615">                }</span>
<span class="nc" id="L616">            });</span>

<span class="nc" id="L618">            entryLogger.flush();</span>

<span class="nc" id="L620">            long batchFlushStarTime = System.nanoTime();</span>
<span class="nc" id="L621">            batch.flush();</span>
<span class="nc" id="L622">            batch.close();</span>
<span class="nc bnc" id="L623" title="All 2 branches missed.">            if (log.isDebugEnabled()) {</span>
<span class="nc" id="L624">                log.debug(&quot;DB batch flushed time : {} s&quot;,</span>
<span class="nc" id="L625">                        MathUtils.elapsedNanos(batchFlushStarTime) / (double) TimeUnit.SECONDS.toNanos(1));</span>
            }

<span class="nc" id="L628">            ledgerIndex.flush();</span>

<span class="nc" id="L630">            cleanupExecutor.execute(() -&gt; {</span>
                // There can only be one single cleanup task running because the cleanupExecutor
                // is single-threaded
                try {
<span class="nc bnc" id="L634" title="All 2 branches missed.">                    if (log.isDebugEnabled()) {</span>
<span class="nc" id="L635">                        log.debug(&quot;Removing deleted ledgers from db indexes&quot;);</span>
                    }

<span class="nc" id="L638">                    entryLocationIndex.removeOffsetFromDeletedLedgers();</span>
<span class="nc" id="L639">                    ledgerIndex.removeDeletedLedgers();</span>
<span class="nc" id="L640">                } catch (Throwable t) {</span>
<span class="nc" id="L641">                    log.warn(&quot;Failed to cleanup db indexes&quot;, t);</span>
<span class="nc" id="L642">                }</span>
<span class="nc" id="L643">            });</span>

<span class="nc" id="L645">            lastCheckpoint = thisCheckpoint;</span>

            // Discard all the entry from the write cache, since they're now persisted
<span class="nc" id="L648">            writeCacheBeingFlushed.clear();</span>

<span class="nc" id="L650">            double flushTimeSeconds = MathUtils.elapsedNanos(startTime) / (double) TimeUnit.SECONDS.toNanos(1);</span>
<span class="nc" id="L651">            double flushThroughput = sizeToFlush / 1024.0 / 1024.0 / flushTimeSeconds;</span>

<span class="nc bnc" id="L653" title="All 2 branches missed.">            if (log.isDebugEnabled()) {</span>
<span class="nc" id="L654">                log.debug(&quot;Flushing done time {} s -- Written {} MB/s&quot;, flushTimeSeconds, flushThroughput);</span>
            }

<span class="nc" id="L657">            recordSuccessfulEvent(dbLedgerStorageStats.getFlushStats(), startTime);</span>
<span class="nc" id="L658">            dbLedgerStorageStats.getFlushSizeStats().registerSuccessfulValue(sizeToFlush);</span>
<span class="nc" id="L659">        } catch (IOException e) {</span>
            // Leave IOExecption as it is
<span class="nc" id="L661">            throw e;</span>
<span class="nc" id="L662">        } catch (RuntimeException e) {</span>
            // Wrap unchecked exceptions
<span class="nc" id="L664">            throw new IOException(e);</span>
        } finally {
            try {
<span class="nc" id="L667">                isFlushOngoing.set(false);</span>
            } finally {
<span class="nc" id="L669">                flushMutex.unlock();</span>
            }
        }
<span class="nc" id="L672">    }</span>

    /**
     * Swap the current write cache with the replacement cache.
     */
    private void swapWriteCache() {
<span class="nc" id="L678">        long stamp = writeCacheRotationLock.writeLock();</span>
        try {
            // First, swap the current write-cache map with an empty one so that writes will
            // go on unaffected. Only a single flush is happening at the same time
<span class="nc" id="L682">            WriteCache tmp = writeCacheBeingFlushed;</span>
<span class="nc" id="L683">            writeCacheBeingFlushed = writeCache;</span>
<span class="nc" id="L684">            writeCache = tmp;</span>

            // since the cache is switched, we can allow flush to be triggered
<span class="nc" id="L687">            hasFlushBeenTriggered.set(false);</span>
        } finally {
            try {
<span class="nc" id="L690">                isFlushOngoing.set(true);</span>
            } finally {
<span class="nc" id="L692">                writeCacheRotationLock.unlockWrite(stamp);</span>
            }
        }
<span class="nc" id="L695">    }</span>

    @Override
    public void flush() throws IOException {
<span class="nc" id="L699">        Checkpoint cp = checkpointSource.newCheckpoint();</span>
<span class="nc" id="L700">        checkpoint(cp);</span>
<span class="nc" id="L701">        checkpointSource.checkpointComplete(cp, true);</span>
<span class="nc" id="L702">    }</span>

    @Override
    public void deleteLedger(long ledgerId) throws IOException {
<span class="nc bnc" id="L706" title="All 2 branches missed.">        if (log.isDebugEnabled()) {</span>
<span class="nc" id="L707">            log.debug(&quot;Deleting ledger {}&quot;, ledgerId);</span>
        }

        // Delete entries from this ledger that are still in the write cache
<span class="nc" id="L711">        long stamp = writeCacheRotationLock.readLock();</span>
        try {
<span class="nc" id="L713">            writeCache.deleteLedger(ledgerId);</span>
        } finally {
<span class="nc" id="L715">            writeCacheRotationLock.unlockRead(stamp);</span>
        }

<span class="nc" id="L718">        entryLocationIndex.delete(ledgerId);</span>
<span class="nc" id="L719">        ledgerIndex.delete(ledgerId);</span>

<span class="nc bnc" id="L721" title="All 2 branches missed.">        for (int i = 0, size = ledgerDeletionListeners.size(); i &lt; size; i++) {</span>
<span class="nc" id="L722">            LedgerDeletionListener listener = ledgerDeletionListeners.get(i);</span>
<span class="nc" id="L723">            listener.ledgerDeleted(ledgerId);</span>
        }

<span class="nc" id="L726">        TransientLedgerInfo tli = transientLedgerInfoCache.remove(ledgerId);</span>
<span class="nc bnc" id="L727" title="All 2 branches missed.">        if (tli != null) {</span>
<span class="nc" id="L728">            tli.close();</span>
        }
<span class="nc" id="L730">    }</span>

    @Override
    public Iterable&lt;Long&gt; getActiveLedgersInRange(long firstLedgerId, long lastLedgerId) throws IOException {
<span class="nc" id="L734">        return ledgerIndex.getActiveLedgersInRange(firstLedgerId, lastLedgerId);</span>
    }

    @Override
    public void updateEntriesLocations(Iterable&lt;EntryLocation&gt; locations) throws IOException {
        // Trigger a flush to have all the entries being compacted in the db storage
<span class="nc" id="L740">        flush();</span>

<span class="nc" id="L742">        entryLocationIndex.updateLocations(locations);</span>
<span class="nc" id="L743">    }</span>

    @Override
    public EntryLogger getEntryLogger() {
<span class="nc" id="L747">        return entryLogger;</span>
    }

    @Override
    public long getLastAddConfirmed(long ledgerId) throws IOException {
<span class="nc" id="L752">        TransientLedgerInfo ledgerInfo = transientLedgerInfoCache.get(ledgerId);</span>
<span class="nc bnc" id="L753" title="All 2 branches missed.">        long lac = null != ledgerInfo ? ledgerInfo.getLastAddConfirmed() : TransientLedgerInfo.NOT_ASSIGNED_LAC;</span>
<span class="nc bnc" id="L754" title="All 2 branches missed.">        if (lac == TransientLedgerInfo.NOT_ASSIGNED_LAC) {</span>
<span class="nc" id="L755">            ByteBuf bb = getEntry(ledgerId, BookieProtocol.LAST_ADD_CONFIRMED);</span>
            try {
<span class="nc" id="L757">                bb.skipBytes(2 * Long.BYTES); // skip ledger id and entry id</span>
<span class="nc" id="L758">                lac = bb.readLong();</span>
<span class="nc" id="L759">                lac = getOrAddLedgerInfo(ledgerId).setLastAddConfirmed(lac);</span>
            } finally {
<span class="nc" id="L761">                bb.release();</span>
            }
        }
<span class="nc" id="L764">        return lac;</span>
    }

    @Override
    public boolean waitForLastAddConfirmedUpdate(long ledgerId, long previousLAC,
            Watcher&lt;LastAddConfirmedUpdateNotification&gt; watcher) throws IOException {
<span class="nc" id="L770">        return getOrAddLedgerInfo(ledgerId).waitForLastAddConfirmedUpdate(previousLAC, watcher);</span>
    }

    @Override
    public void cancelWaitForLastAddConfirmedUpdate(long ledgerId,
                                                    Watcher&lt;LastAddConfirmedUpdateNotification&gt; watcher)
            throws IOException {
<span class="nc" id="L777">        getOrAddLedgerInfo(ledgerId).cancelWaitForLastAddConfirmedUpdate(watcher);</span>
<span class="nc" id="L778">    }</span>

    @Override
    public void setExplicitLac(long ledgerId, ByteBuf lac) throws IOException {
<span class="nc" id="L782">        TransientLedgerInfo ledgerInfo = getOrAddLedgerInfo(ledgerId);</span>
<span class="nc" id="L783">        ledgerInfo.setExplicitLac(lac);</span>
<span class="nc" id="L784">        ledgerIndex.setExplicitLac(ledgerId, lac);</span>
<span class="nc" id="L785">        ledgerInfo.notifyWatchers(Long.MAX_VALUE);</span>
<span class="nc" id="L786">    }</span>

    @Override
    public ByteBuf getExplicitLac(long ledgerId) throws IOException {
<span class="nc bnc" id="L790" title="All 2 branches missed.">        if (log.isDebugEnabled()) {</span>
<span class="nc" id="L791">            log.debug(&quot;getExplicitLac ledger {}&quot;, ledgerId);</span>
        }
<span class="nc" id="L793">        TransientLedgerInfo ledgerInfo = getOrAddLedgerInfo(ledgerId);</span>
<span class="nc bnc" id="L794" title="All 2 branches missed.">        if (ledgerInfo.getExplicitLac() != null) {</span>
<span class="nc bnc" id="L795" title="All 2 branches missed.">            if (log.isDebugEnabled()) {</span>
<span class="nc" id="L796">                log.debug(&quot;getExplicitLac ledger {} returned from TransientLedgerInfo&quot;, ledgerId);</span>
            }
<span class="nc" id="L798">            return ledgerInfo.getExplicitLac();</span>
        }
<span class="nc" id="L800">        LedgerData ledgerData = ledgerIndex.get(ledgerId);</span>
<span class="nc bnc" id="L801" title="All 2 branches missed.">        if (!ledgerData.hasExplicitLac()) {</span>
<span class="nc bnc" id="L802" title="All 2 branches missed.">            if (log.isDebugEnabled()) {</span>
<span class="nc" id="L803">                log.debug(&quot;getExplicitLac ledger {} missing from LedgerData&quot;, ledgerId);</span>
            }
<span class="nc" id="L805">            return null;</span>
        }
<span class="nc bnc" id="L807" title="All 2 branches missed.">        if (ledgerData.hasExplicitLac()) {</span>
<span class="nc bnc" id="L808" title="All 2 branches missed.">            if (log.isDebugEnabled()) {</span>
<span class="nc" id="L809">                log.debug(&quot;getExplicitLac ledger {} returned from LedgerData&quot;, ledgerId);</span>
            }
<span class="nc" id="L811">            ByteString persistedLac = ledgerData.getExplicitLac();</span>
<span class="nc" id="L812">            ledgerInfo.setExplicitLac(Unpooled.wrappedBuffer(persistedLac.toByteArray()));</span>
        }
<span class="nc" id="L814">        return ledgerInfo.getExplicitLac();</span>
    }

    private TransientLedgerInfo getOrAddLedgerInfo(long ledgerId) {
<span class="nc" id="L818">        return transientLedgerInfoCache.computeIfAbsent(ledgerId, l -&gt; {</span>
<span class="nc" id="L819">            return new TransientLedgerInfo(l, ledgerIndex);</span>
        });
    }

    private void updateCachedLacIfNeeded(long ledgerId, long lac) {
<span class="nc" id="L824">        TransientLedgerInfo tli = transientLedgerInfoCache.get(ledgerId);</span>
<span class="nc bnc" id="L825" title="All 2 branches missed.">        if (tli != null) {</span>
<span class="nc" id="L826">            tli.setLastAddConfirmed(lac);</span>
        }
<span class="nc" id="L828">    }</span>

    @Override
    public void flushEntriesLocationsIndex() throws IOException {
        // No-op. Location index is already flushed in updateEntriesLocations() call
<span class="nc" id="L833">    }</span>

    /**
     * Add an already existing ledger to the index.
     *
     * &lt;p&gt;This method is only used as a tool to help the migration from InterleaveLedgerStorage to DbLedgerStorage
     *
     * @param ledgerId
     *            the ledger id
     * @param pages
     *            Iterator over index pages from Indexed
     * @return the number of
     */
    public long addLedgerToIndex(long ledgerId, boolean isFenced, byte[] masterKey,
            LedgerCache.PageEntriesIterable pages) throws Exception {
<span class="nc" id="L848">        LedgerData ledgerData = LedgerData.newBuilder().setExists(true).setFenced(isFenced)</span>
<span class="nc" id="L849">                .setMasterKey(ByteString.copyFrom(masterKey)).build();</span>
<span class="nc" id="L850">        ledgerIndex.set(ledgerId, ledgerData);</span>
<span class="nc" id="L851">        MutableLong numberOfEntries = new MutableLong();</span>

        // Iterate over all the entries pages
<span class="nc" id="L854">        Batch batch = entryLocationIndex.newBatch();</span>
<span class="nc bnc" id="L855" title="All 2 branches missed.">        for (LedgerCache.PageEntries page: pages) {</span>
<span class="nc" id="L856">            try (LedgerEntryPage lep = page.getLEP()) {</span>
<span class="nc" id="L857">                lep.getEntries((entryId, location) -&gt; {</span>
<span class="nc" id="L858">                    entryLocationIndex.addLocation(batch, ledgerId, entryId, location);</span>
<span class="nc" id="L859">                    numberOfEntries.increment();</span>
<span class="nc" id="L860">                    return true;</span>
                });
            }
<span class="nc" id="L863">        }</span>

<span class="nc" id="L865">        batch.flush();</span>
<span class="nc" id="L866">        batch.close();</span>

<span class="nc" id="L868">        return numberOfEntries.longValue();</span>
    }

    @Override
    public void registerLedgerDeletionListener(LedgerDeletionListener listener) {
<span class="nc" id="L873">        ledgerDeletionListeners.add(listener);</span>
<span class="nc" id="L874">    }</span>

    public EntryLocationIndex getEntryLocationIndex() {
<span class="nc" id="L877">        return entryLocationIndex;</span>
    }

    private void recordSuccessfulEvent(OpStatsLogger logger, long startTimeNanos) {
<span class="nc" id="L881">        logger.registerSuccessfulEvent(MathUtils.elapsedNanos(startTimeNanos), TimeUnit.NANOSECONDS);</span>
<span class="nc" id="L882">    }</span>

    private void recordFailedEvent(OpStatsLogger logger, long startTimeNanos) {
<span class="nc" id="L885">        logger.registerFailedEvent(MathUtils.elapsedNanos(startTimeNanos), TimeUnit.NANOSECONDS);</span>
<span class="nc" id="L886">    }</span>

    long getWriteCacheSize() {
<span class="nc" id="L889">        return writeCache.size() + writeCacheBeingFlushed.size();</span>
    }

    long getWriteCacheCount() {
<span class="nc" id="L893">        return writeCache.count() + writeCacheBeingFlushed.count();</span>
    }

    long getReadCacheSize() {
<span class="nc" id="L897">        return readCache.size();</span>
    }

    long getReadCacheCount() {
<span class="nc" id="L901">        return readCache.count();</span>
    }

    @Override
    public List&lt;GarbageCollectionStatus&gt; getGarbageCollectionStatus() {
<span class="nc" id="L906">        return Collections.singletonList(gcThread.getGarbageCollectionStatus());</span>
    }

    /**
     * Interface which process ledger logger.
     */
    public interface LedgerLoggerProcessor {
        void process(long entryId, long entryLogId, long position);
    }

<span class="nc" id="L916">    private static final Logger log = LoggerFactory.getLogger(SingleDirectoryDbLedgerStorage.class);</span>

    @Override
    public OfLong getListOfEntriesOfLedger(long ledgerId) throws IOException {
<span class="nc" id="L920">        throw new UnsupportedOperationException(</span>
                &quot;getListOfEntriesOfLedger method is currently unsupported for SingleDirectoryDbLedgerStorage&quot;);
    }

    private LedgerDirsManager.LedgerDirsListener getLedgerDirsListener() {
<span class="nc" id="L925">        return new LedgerDirsListener() {</span>

            @Override
            public void diskAlmostFull(File disk) {
<span class="nc bnc" id="L929" title="All 2 branches missed.">                if (gcThread.isForceGCAllowWhenNoSpace()) {</span>
<span class="nc" id="L930">                    gcThread.enableForceGC();</span>
                } else {
<span class="nc" id="L932">                    gcThread.suspendMajorGC();</span>
                }
<span class="nc" id="L934">            }</span>

            @Override
            public void diskFull(File disk) {
<span class="nc bnc" id="L938" title="All 2 branches missed.">                if (gcThread.isForceGCAllowWhenNoSpace()) {</span>
<span class="nc" id="L939">                    gcThread.enableForceGC();</span>
                } else {
<span class="nc" id="L941">                    gcThread.suspendMajorGC();</span>
<span class="nc" id="L942">                    gcThread.suspendMinorGC();</span>
                }
<span class="nc" id="L944">            }</span>

            @Override
            public void allDisksFull(boolean highPriorityWritesAllowed) {
<span class="nc bnc" id="L948" title="All 2 branches missed.">                if (gcThread.isForceGCAllowWhenNoSpace()) {</span>
<span class="nc" id="L949">                    gcThread.enableForceGC();</span>
                } else {
<span class="nc" id="L951">                    gcThread.suspendMajorGC();</span>
<span class="nc" id="L952">                    gcThread.suspendMinorGC();</span>
                }
<span class="nc" id="L954">            }</span>

            @Override
            public void diskWritable(File disk) {
                // we have enough space now
<span class="nc bnc" id="L959" title="All 2 branches missed.">                if (gcThread.isForceGCAllowWhenNoSpace()) {</span>
                    // disable force gc.
<span class="nc" id="L961">                    gcThread.disableForceGC();</span>
                } else {
                    // resume compaction to normal.
<span class="nc" id="L964">                    gcThread.resumeMajorGC();</span>
<span class="nc" id="L965">                    gcThread.resumeMinorGC();</span>
                }
<span class="nc" id="L967">            }</span>

            @Override
            public void diskJustWritable(File disk) {
<span class="nc bnc" id="L971" title="All 2 branches missed.">                if (gcThread.isForceGCAllowWhenNoSpace()) {</span>
                    // if a disk is just writable, we still need force gc.
<span class="nc" id="L973">                    gcThread.enableForceGC();</span>
                } else {
                    // still under warn threshold, only resume minor compaction.
<span class="nc" id="L976">                    gcThread.resumeMinorGC();</span>
                }
<span class="nc" id="L978">            }</span>
        };
    }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.4.201905082037</span></div></body></html>